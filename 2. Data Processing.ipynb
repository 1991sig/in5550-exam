{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.runners.interactive import interactive_runner\n",
    "import apache_beam.runners.interactive.interactive_beam as ib\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial Processing of the Data\n",
    "\n",
    "Using a `DoFN` to structure the data. `form`, `properties.lemma`, `properties.xpos` for each `node` is extracted and accumulated in lists.\n",
    "\n",
    "Steps:\n",
    "1. If there is no negation in the sentence, add a list with `\"T\"` tags for each token in the sentence.\n",
    "\n",
    "2. If there is one negation cue in the sentence, accumulate the unprocessed `negation` values in a list to process later.\n",
    "\n",
    "3. If there are two or more negation cues in the sentence, accumulate the unprocessed `negation` values in separate lists according to the `negation.id` value. Return one copy of the sentence per `negation.id` value, with the corresponding negation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractJSON(beam.DoFn):\n",
    "    \"\"\"Extract JSON for each line.\"\"\"\n",
    "\n",
    "    def process(self, e):\n",
    "        \"\"\"Process a sentence.\"\"\"\n",
    "        e = json.loads(e)\n",
    "\n",
    "        if e[\"negations\"] == 0:\n",
    "\n",
    "            # Process fields and add \"T\" tags\n",
    "\n",
    "            fields = dict(\n",
    "                zip(\n",
    "                    (\"form\", \"lemma\", \"xpos\", \"negation\"),\n",
    "                    [list(t) for t in zip(*[\n",
    "                        [n[\"form\"],\n",
    "                         n[\"properties\"][\"lemma\"],\n",
    "                         n[\"properties\"][\"xpos\"],\n",
    "                         \"T\"] for n in e.get(\"nodes\")])]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Remove the nodes fields\n",
    "            e.pop(\"nodes\")\n",
    "\n",
    "            # Insert new fields\n",
    "            e.update(fields)\n",
    "\n",
    "            yield e\n",
    "        else:\n",
    "\n",
    "            # Process Fields\n",
    "            fields = defaultdict(list)\n",
    "            negs = defaultdict(list)\n",
    "            for i in e.get(\"nodes\"):\n",
    "                fields[\"form\"].append(i[\"form\"])\n",
    "                fields[\"lemma\"].append(i[\"properties\"][\"lemma\"])\n",
    "                fields[\"xpos\"].append(i[\"properties\"][\"xpos\"])\n",
    "\n",
    "                # Process the negation tags\n",
    "                for j, k in enumerate(i.get(\"negation\")):\n",
    "                    negs[k[\"id\"]].append(k)\n",
    "\n",
    "            e.pop(\"nodes\")\n",
    "            e.update(dict(fields))\n",
    "\n",
    "            # Output one copy of sentence for each set of cue + tags\n",
    "            for v in negs.values():\n",
    "                e[\"negation\"] = v\n",
    "                yield e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Processing the Negation Tokens\n",
    "\n",
    "1. If there is no negation in the sentence, from the previous step we know the negation field is ready\n",
    "\n",
    "2. If there is a negation, label the negation cues for each token as follows:\n",
    "    - `cue` is in the dict?\n",
    "        - Yes --> label `\"C\"`\n",
    "        - No:\n",
    "            - `scope` is in the dict?\n",
    "                - Yes --> label `\"F\"`\n",
    "                - No --> label `\"T\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessNegations(beam.DoFn):\n",
    "    \"\"\"Process negations to 4 labels.\n",
    "\n",
    "    Negations are labeled as one of [\"C\", \"A\", \"F\", \"T\"].\n",
    "    \"\"\"\n",
    "\n",
    "    def process(self, e):\n",
    "        \"\"\"Process labels.\n",
    "\n",
    "        If 0 negations, the labels are ready\n",
    "        from the previous step.\n",
    "        \"\"\"\n",
    "        if e[\"negations\"] == 0:\n",
    "            n_t = len(e[\"negation\"])\n",
    "            e[\"cue\"] = [\"\"] * n_t\n",
    "            e[\"scope\"] = [\"\"] * n_t\n",
    "            yield e\n",
    "        else:\n",
    "            neg_old = e.pop(\"negation\")\n",
    "            neg_new = defaultdict(list)\n",
    "            \n",
    "            for f, n in zip(e[\"form\"], neg_old):\n",
    "                neg_new[\"cue\"].append(n.get(\"cue\", \"\"))\n",
    "                neg_new[\"scope\"].append(n.get(\"scope\", \"\"))\n",
    "                if \"cue\" in n:\n",
    "                    if n[\"cue\"] != f and \"scope\" in n:\n",
    "                        neg_new[\"negation\"].append(\"A\")\n",
    "                    else:\n",
    "                        neg_new[\"negation\"].append(\"C\")\n",
    "                else:\n",
    "                    if \"scope\" in n:\n",
    "                        neg_new[\"negation\"].append(\"F\")\n",
    "                    else:\n",
    "                        neg_new[\"negation\"].append(\"T\")\n",
    "\n",
    "            e.update(dict(neg_new))\n",
    "            yield e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ProcessToTFRecord(beam.DoFn):\n",
    "\n",
    "    def tf_ex(self, e):\n",
    "        cont = tf.train.Features(\n",
    "            feature={\n",
    "            \"id\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[e[\"id\"].encode(\"utf-8\")])),\n",
    "            \"source\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[e[\"source\"].encode(\"utf-8\")])),\n",
    "            \"negations\": tf.train.Feature(int64_list=tf.train.Int64List(value=[e[\"negations\"]]))\n",
    "        })\n",
    "        \n",
    "\n",
    "        form_fs = []\n",
    "        lemma_fs = []\n",
    "        xpos_fs = []\n",
    "        cue_fs = []\n",
    "        scope_fs = []\n",
    "        neg_fs = []\n",
    "        \n",
    "        form = e[\"form\"]\n",
    "        lemma = e[\"lemma\"]\n",
    "        xpos = e[\"xpos\"]\n",
    "        cue = e[\"cue\"]\n",
    "        scope = e[\"scope\"]\n",
    "        neg = e[\"negation\"]\n",
    "        \n",
    "        \n",
    "        for f, l, x, c, s, n in zip(form, lemma, xpos, cue, scope, neg):\n",
    "            # create each of the features, then add them to the corresponding feature list\n",
    "            f_f = tf.train.Feature(bytes_list=tf.train.BytesList(value=[f.encode(\"utf-8\")]))\n",
    "            form_fs.append(f_f)\n",
    "            \n",
    "            l_f = tf.train.Feature(bytes_list=tf.train.BytesList(value=[l.encode(\"utf-8\")]))\n",
    "            lemma_fs.append(l_f)\n",
    "            \n",
    "            x_f = tf.train.Feature(bytes_list=tf.train.BytesList(value=[x.encode(\"utf-8\")]))\n",
    "            xpos_fs.append(x_f)\n",
    "            \n",
    "            c_f = tf.train.Feature(bytes_list=tf.train.BytesList(value=[c.encode(\"utf-8\")]))\n",
    "            cue_fs.append(c_f)\n",
    "            \n",
    "            s_f = tf.train.Feature(bytes_list=tf.train.BytesList(value=[s.encode(\"utf-8\")]))\n",
    "            scope_fs.append(s_f)\n",
    "            \n",
    "            n_f = tf.train.Feature(bytes_list=tf.train.BytesList(value=[n.encode(\"utf-8\")]))\n",
    "            neg_fs.append(n_f)\n",
    "        \n",
    "        form = tf.train.FeatureList(feature=form_fs)\n",
    "        lemma = tf.train.FeatureList(feature=lemma_fs)\n",
    "        xpos = tf.train.FeatureList(feature=xpos_fs)\n",
    "        cue = tf.train.FeatureList(feature=cue_fs)\n",
    "        scope = tf.train.FeatureList(feature=scope_fs)\n",
    "        neg = tf.train.FeatureList(feature=neg_fs)\n",
    "\n",
    "        feats = tf.train.FeatureLists(feature_list={\n",
    "            \"form\": form,\n",
    "            \"lemma\": lemma, \n",
    "            \"xpos\": xpos,\n",
    "            \"cue\": cue,\n",
    "            \"scope\": scope,\n",
    "            \"negation\": neg\n",
    "        })\n",
    "\n",
    "        ex = tf.train.SequenceExample(context=cont,\n",
    "                                      feature_lists=feats)\n",
    "\n",
    "        return ex\n",
    "\n",
    "    def process(self, e):\n",
    "        ex = self.tf_ex(e)\n",
    "        yield ex.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. \"Putting It All Together\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(src, dst):\n",
    "    \"\"\"Process data and save to file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        The source file to process\n",
    "    dst : str\n",
    "        The destination file to output\n",
    "        processed data\n",
    "    \"\"\"\n",
    "    pref, suff = dst.rsplit(\".\")\n",
    "    p = beam.Pipeline(interactive_runner.InteractiveRunner())\n",
    "    sentences = (\n",
    "        p\n",
    "        | \"Read Lines\" >> beam.io.ReadFromText(src)\n",
    "        | \"Extract Data\" >> beam.ParDo(ExtractJSON())\n",
    "        | \"Process Labels\" >> beam.ParDo(ProcessNegations())\n",
    "        | \"Format JSON\" >> beam.Map(json.dumps)\n",
    "        | \"Write File\" >> beam.io.WriteToText(pref, \".\" + suff)\n",
    "    )\n",
    "    \n",
    "    p.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_to_list(src):\n",
    "    \"\"\"Process data and return list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        The source file to process\n",
    "    \"\"\"\n",
    "    p = beam.Pipeline(interactive_runner.InteractiveRunner())\n",
    "    sentences = (\n",
    "        p\n",
    "        | \"Read Lines\" >> beam.io.ReadFromText(src)\n",
    "        | \"Extract Data\" >> beam.ParDo(ExtractJSON())\n",
    "        | \"Process Labels\" >> beam.ParDo(ProcessNegations())\n",
    "    )\n",
    "    \n",
    "    res = p.run()\n",
    "    sents = res.get(sentences)\n",
    "    return sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_to_TF(src, dst):\n",
    "    \"\"\"Process data and save to file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        The source file to process\n",
    "    dst : str\n",
    "        The destination file to output\n",
    "        processed data\n",
    "    \"\"\"\n",
    "    pref, suff = dst.rsplit(\".\")\n",
    "    p = beam.Pipeline(interactive_runner.InteractiveRunner())\n",
    "    sentences = (\n",
    "        p\n",
    "        | \"Read Lines\" >> beam.io.ReadFromText(src)\n",
    "        | \"Extract Data\" >> beam.ParDo(ExtractJSON())\n",
    "        | \"Process Labels\" >> beam.ParDo(ProcessNegations())\n",
    "        | \"Write File\" >> beam.io.WriteToTFRecord(pref)\n",
    "    )\n",
    "\n",
    "    p.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Files\n",
    "\n",
    "1. The dev data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "digraph G {\n",
       "node [color=blue, fontcolor=blue, shape=box];\n",
       "\"Read Lines\";\n",
       "pcoll9236 [label=\"\", shape=circle];\n",
       "\"Extract Data\";\n",
       "pcoll9385 [label=\"\", shape=circle];\n",
       "\"Process Labels\";\n",
       "pcoll7744 [label=\"\", shape=circle];\n",
       "\"Format JSON\";\n",
       "pcoll479 [label=\"\", shape=circle];\n",
       "\"Write File\";\n",
       "pcoll5554 [label=\"\", shape=circle];\n",
       "\"Read Lines\" -> pcoll9236;\n",
       "pcoll9236 -> \"Extract Data\";\n",
       "\"Extract Data\" -> pcoll9385;\n",
       "pcoll9385 -> \"Process Labels\";\n",
       "\"Process Labels\" -> pcoll7744;\n",
       "pcoll7744 -> \"Format JSON\";\n",
       "\"Format JSON\" -> pcoll479;\n",
       "pcoll479 -> \"Write File\";\n",
       "\"Write File\" -> pcoll5554;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_data(src=\"negation/cdd.epe\", \n",
    "             dst=\"Data/dev.epe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The training data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "digraph G {\n",
       "node [color=blue, fontcolor=blue, shape=box];\n",
       "\"Read Lines\";\n",
       "pcoll9236 [label=\"\", shape=circle];\n",
       "\"Extract Data\";\n",
       "pcoll9385 [label=\"\", shape=circle];\n",
       "\"Process Labels\";\n",
       "pcoll7744 [label=\"\", shape=circle];\n",
       "\"Format JSON\";\n",
       "pcoll479 [label=\"\", shape=circle];\n",
       "\"Write File\";\n",
       "pcoll5554 [label=\"\", shape=circle];\n",
       "\"Read Lines\" -> pcoll9236;\n",
       "pcoll9236 -> \"Extract Data\";\n",
       "\"Extract Data\" -> pcoll9385;\n",
       "pcoll9385 -> \"Process Labels\";\n",
       "\"Process Labels\" -> pcoll7744;\n",
       "pcoll7744 -> \"Format JSON\";\n",
       "\"Format JSON\" -> pcoll479;\n",
       "pcoll479 -> \"Write File\";\n",
       "\"Write File\" -> pcoll5554;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_data(src=\"negation/cdt.epe\",\n",
    "             dst=\"Data/train.epe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The evaluation data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "digraph G {\n",
       "node [color=blue, fontcolor=blue, shape=box];\n",
       "\"Read Lines\";\n",
       "pcoll9236 [label=\"\", shape=circle];\n",
       "\"Extract Data\";\n",
       "pcoll9385 [label=\"\", shape=circle];\n",
       "\"Process Labels\";\n",
       "pcoll7744 [label=\"\", shape=circle];\n",
       "\"Format JSON\";\n",
       "pcoll479 [label=\"\", shape=circle];\n",
       "\"Write File\";\n",
       "pcoll5554 [label=\"\", shape=circle];\n",
       "\"Read Lines\" -> pcoll9236;\n",
       "pcoll9236 -> \"Extract Data\";\n",
       "\"Extract Data\" -> pcoll9385;\n",
       "pcoll9385 -> \"Process Labels\";\n",
       "\"Process Labels\" -> pcoll7744;\n",
       "pcoll7744 -> \"Format JSON\";\n",
       "\"Format JSON\" -> pcoll479;\n",
       "pcoll479 -> \"Write File\";\n",
       "\"Write File\" -> pcoll5554;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_data(src=\"negation/cde.epe\",\n",
    "             dst=\"Data/eval.epe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Format:\n",
    "\n",
    "The example below shows the new format of the sentences:\n",
    "\n",
    "```javascript\n",
    "{\n",
    "    \"id\": \"0\", \n",
    "    \"source\": \"wisteria01\",\n",
    "    \"negations\": 0,\n",
    "    \"form\": [\"1.\", \"The\", \"Singular\", \"Experience\", \"of\", \"Mr.\", \"John\", \"Scott\", \"Eccles\"],\n",
    "    \"lemma\": [\"1.\", \"The\", \"Singular\", \"Experience\", \"of\", \"Mr.\", \"John\", \"Scott\", \"Eccles\"],\n",
    "    \"xpos\": [\"CD\", \"NNP\", \"NNP\", \"NN\", \"IN\", \"NNP\", \"NNP\", \"NNP\", \"NNP\"],\n",
    "    \"negation\": [\"T\", \"T\", \"T\", \"T\", \"T\", \"T\", \"T\", \"T\", \"T\"],\n",
    "    \"cue\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "    \"scope\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
