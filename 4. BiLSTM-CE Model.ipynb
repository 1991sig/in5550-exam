{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"exambert.ipynb","provenance":[],"collapsed_sections":["fggpXjOZ6t9Q","2xWuMQ_UPiX1"],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1rmcYUzXYOyPkmk0oAq75uf6PtHo4EAEE","authorship_tag":"ABX9TyOld3b9ppS6/KDPtDOGaDCD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"t8RT0mgXkhO4","colab_type":"code","colab":{}},"source":["!pip install torchtext --upgrade"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jiXdtk5slSNK","colab_type":"code","colab":{}},"source":["!pip install transformers --upgrade"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9NFqRHrl-pG","colab_type":"code","outputId":"d2945b5b-aee6-4009-83a5-61c369a2d831","executionInfo":{"status":"ok","timestamp":1589201751859,"user_tz":-120,"elapsed":703,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/\"My Drive\"/in5550-exam"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/in5550-exam\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-ChqFe8amMIm","colab_type":"code","colab":{}},"source":["import argparse\n","import random\n","import torch\n","import torchtext\n","from torchtext import data\n","import NSR\n","import os\n","import json\n","import numpy as np\n","\n","SEED = 2020\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jzkdQsH7z2Ua","colab_type":"code","colab":{}},"source":["from transformers import BertConfig\n","\n","config = BertConfig.from_pretrained('bert-base-cased')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Y2a8QQLz8Rp","colab_type":"code","outputId":"a0c9b5b3-16b1-4e15-9784-06c304780ce7","executionInfo":{"status":"ok","timestamp":1589149792416,"user_tz":-120,"elapsed":1942,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["config"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"AuJkozUMM7SB","colab_type":"code","colab":{}},"source":["emb_dim = config.hidden_size"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yC_ncY8cmnIJ","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer\n","\n","tokenbert = BertTokenizer.from_pretrained('bert-base-cased', \n","                                          do_lower_case=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fggpXjOZ6t9Q","colab_type":"text"},"source":["# Preprocessing the data for BERT"]},{"cell_type":"code","metadata":{"id":"JoG6JG1W6srn","colab_type":"code","colab":{}},"source":["def Prep4BERT(datafile):\n","  fpart, suff = datafile.rsplit(\".\", 1)\n","  outfile = fpart + \"_bert.\" + suff\n","  if os.path.isfile(outfile):\n","    raise Exception(\"The file already exists\")\n","\n","  with open(datafile) as f, open(outfile, \"wt\") as o:\n","    for line in f:\n","      ex = json.loads(line)\n","      b_form = [[tokenbert.convert_tokens_to_ids(t) for t in tokenbert.tokenize(w)] for w in ex[\"form\"]]\n","      b_cue = [[tokenbert.convert_tokens_to_ids(t) for t in tokenbert.tokenize(w)] for w in ex[\"cue\"]]\n","      ex[\"form\"] = b_form\n","      ex[\"cue\"] = b_cue\n","      json.dump(ex, o)\n","      o.write(\"\\n\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UetuWcHCB1UH","colab_type":"code","colab":{}},"source":["# Prep4BERT(\"DataFiles/cdd.epe\")\n","# Prep4BERT(\"DataFiles/cdt.epe\")\n","# Prep4BERT(\"DataFiles/cde.epe\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hdh0858MSRXx","colab_type":"text"},"source":["# Set Up Data"]},{"cell_type":"code","metadata":{"id":"IBOYpq6-mYV9","colab_type":"code","colab":{}},"source":["ID = data.RawField(preprocessing=lambda x: int(x))\n","SRC = data.RawField()\n","NEGS = data.RawField(preprocessing=lambda x: int(x))\n","\n","FORM = data.Field(batch_first = True,\n","                  include_lengths = True,\n","                  use_vocab = False,\n","                  tokenize=tokenbert.tokenize,\n","                  preprocessing=tokenbert.convert_tokens_to_ids,\n","                  init_token = tokenbert.cls_token_id,\n","                  eos_token = tokenbert.sep_token_id,\n","                  pad_token = tokenbert.pad_token_id,\n","                  unk_token = tokenbert.unk_token_id)\n","\n","LEMMA = data.RawField()\n","XPOS = data.RawField()\n","LABS = data.Field(batch_first=True, \n","                  unk_token=None)\n","\n","CUE = data.Field(batch_first = True,\n","                 include_lengths = False,\n","                 use_vocab = False,\n","                 tokenize=tokenbert.tokenize,\n","                 preprocessing=tokenbert.convert_tokens_to_ids,\n","                 init_token = tokenbert.cls_token_id,\n","                 eos_token = tokenbert.sep_token_id,\n","                 pad_token = tokenbert.pad_token_id,\n","                 unk_token = tokenbert.unk_token_id)\n","\n","SCOPE = data.RawField()\n","\n","fields = {\n","    \"id\": (\"id\", ID),\n","    \"source\": (\"source\", SRC),\n","    \"negations\": (\"negations\", NEGS),\n","    \"form\": (\"form\", FORM),\n","    \"lemma\": (\"lemma\", LEMMA),\n","    \"xpos\": (\"xpos\", XPOS),\n","    \"negation\": (\"label\", LABS),\n","    \"cue\": (\"cue\", CUE),\n","    \"scope\": (\"scope\", SCOPE),\n","}\n","\n","Xtrain, Xdev = NSR.StarSEM2012.splits(\n","    \"DataFiles\",\n","    fields=fields,\n","    test=None)\n","\n","LABS.build_vocab(Xtrain)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y_KHE7wWJ9x3","colab_type":"code","outputId":"70273374-50f0-4aa2-aa41-b44d60a9082b","executionInfo":{"status":"ok","timestamp":1589149798595,"user_tz":-120,"elapsed":525,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Labels: \", LABS.vocab.stoi)\n","n_k = len(LABS.vocab.stoi)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Labels:  defaultdict(None, {'<pad>': 0, 'T': 1, 'F': 2, 'C': 3, 'A': 4})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5b8IzlUFOZCf","colab_type":"code","outputId":"2b56a8ae-39c7-419a-fa3b-f28646f8337a","executionInfo":{"status":"ok","timestamp":1589149799255,"user_tz":-120,"elapsed":579,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["LABS.vocab.freqs.most_common()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('T', 61351), ('F', 6802), ('C', 843), ('A', 159)]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"reUBAq4bogTy","colab_type":"code","colab":{}},"source":["from transformers import BertModel\n","\n","bert = BertModel.from_pretrained('bert-base-cased')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Eo0Ru-WMNSZ","colab_type":"code","colab":{}},"source":["\"\"\"Bidirectional LSTM sequence labeller based on Fancellu et al. (2016).\"\"\"\n","import torch.nn as nn\n","\n","\n","class BiBERTLSTM(nn.Module):\n","    \"\"\"Bidirectional LSTM model.\n","\n","    Aims to replicate the BiLSTM-C model used by\n","    Fancellu et al. (2016).\n","\n","    Parameters\n","    ----------\n","    input_dim : int\n","        Input dimensions\n","    embedding_dim : int\n","        Dimensionality of word embeddings\n","    n_neurons : int\n","        Number of neurons of the model\n","    output_dim : int\n","        Output dimensions\n","    n_layers : int\n","        Number of hidden layers\n","    bidir : bool\n","        Bidirectional if TRUE\n","    batch_first : bool\n","        If TRUE, inputs are assumed to have shape\n","            [batch size X # tokens]\n","        If FALSE:\n","            [# tokens X batch size]\n","    vecs : torch.Tensor\n","        A tensor with pre-trained word vectors\n","    train_emb : bool\n","        Whether to train the embedding layer further\n","\n","    \"\"\"\n","\n","    def __init__(self, emBERTing, emb_dim, n_neurons, output_dim, n_layers):\n","        \"\"\"Initialize the model.\"\"\"\n","        super().__init__()\n","\n","        self.emBERTing = emBERTing\n","        self.emBERTing.requires_grad_(requires_grad=False)\n","\n","        self.lstm = nn.LSTM(emb_dim,\n","                            n_neurons,\n","                            num_layers=n_layers,\n","                            bidirectional=True,\n","                            batch_first=True)\n","\n","        self.fc = nn.Linear(n_neurons * 2,\n","                            output_dim)\n","\n","        self.dropout = nn.Dropout(p=0.5)\n","\n","    def forward(self, X, C):\n","        \"\"\"Perform a forward pass.\n","\n","        Given sample(s) X, predicts the raw/unscaled class probabilities, which\n","        can then be converted to probabilities by sigmoid or softmax.\n","\n","        Input\n","        -----\n","        X : torch.Tensor or tuple(torch.Tensor, torch.Tensor)\n","\n","        Returns\n","        -------\n","        The linear predicted values, a torch.tensor\n","        with dimension [batchsize X `output_dim`]\n","\n","        \"\"\"\n","        X, lens = X\n","        w_embs, _ = self.emBERTing(X)\n","        c_embs, _ = self.emBERTing(C)\n","        embs = (w_embs + c_embs)[:, 1:-1, :]\n","        lens = lens - 2\n","        pack_emb = nn.utils.rnn.pack_padded_sequence(\n","            embs, lens, batch_first=True, enforce_sorted=False\n","        )\n","        pack_O, _ = self.lstm(pack_emb)\n","        O, _ = nn.utils.rnn.pad_packed_sequence(pack_O, batch_first=True)\n","        O_d = self.dropout(O)\n","        return self.fc(O_d)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WsqSpbeOLtoc","colab_type":"code","outputId":"6609a96e-187d-4827-afd7-df63e5f15367","executionInfo":{"status":"ok","timestamp":1589149807405,"user_tz":-120,"elapsed":4299,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["M = BiBERTLSTM(bert, emb_dim, \n","               n_neurons=250, n_layers=2, \n","               output_dim=n_k)\n","M.cuda()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BiBERTLSTM(\n","  (emBERTing): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (lstm): LSTM(768, 250, num_layers=2, batch_first=True, bidirectional=True)\n","  (fc): Linear(in_features=500, out_features=5, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"BuzG9vjlKIZw","colab_type":"code","outputId":"3ea330e3-212f-4b91-bf6b-d5b427be3c63","executionInfo":{"status":"ok","timestamp":1589149808813,"user_tz":-120,"elapsed":459,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["[i for i, j in M.named_parameters() if j.requires_grad]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['lstm.weight_ih_l0',\n"," 'lstm.weight_hh_l0',\n"," 'lstm.bias_ih_l0',\n"," 'lstm.bias_hh_l0',\n"," 'lstm.weight_ih_l0_reverse',\n"," 'lstm.weight_hh_l0_reverse',\n"," 'lstm.bias_ih_l0_reverse',\n"," 'lstm.bias_hh_l0_reverse',\n"," 'lstm.weight_ih_l1',\n"," 'lstm.weight_hh_l1',\n"," 'lstm.bias_ih_l1',\n"," 'lstm.bias_hh_l1',\n"," 'lstm.weight_ih_l1_reverse',\n"," 'lstm.weight_hh_l1_reverse',\n"," 'lstm.bias_ih_l1_reverse',\n"," 'lstm.bias_hh_l1_reverse',\n"," 'fc.weight',\n"," 'fc.bias']"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"2xWuMQ_UPiX1","colab_type":"text"},"source":["# Run Training"]},{"cell_type":"code","metadata":{"id":"U1w-KRiJPhiJ","colab_type":"code","colab":{}},"source":["from NSR.Runners.AbstractRunner import Runner\n","from NSR.Utils import override, append2dict\n","import tqdm\n","\n","\n","class BERTMultiClassRunner(Runner):\n","    \"\"\"Run training and evaluation workloads for multi-label problems.\n","\n","    Arguments\n","    ---------\n","    model: torch.nn.Module\n","        Model to optimize or test.\n","    criterion: torch.optim\n","        Loss function.\n","    optimizer: torch.optim\n","        Optimizer for weights and biases.\n","    labels: list\n","        List containing the labels in index form.\n","        I.e. the values in the label field vocab.\n","\n","    \"\"\"\n","\n","    def __init__(self, model, criterion, optimizer, labels):\n","        \"\"\"Initialize the MultiClassRunner.\"\"\"\n","        super().__init__(model, criterion, optimizer, labels)\n","\n","    @override\n","    def get_accuracy(self, y_hat, y):\n","        \"\"\"Compute global accuracy.\"\"\"\n","        correct = (y_hat == y).nonzero().size(0)\n","        return correct / y_hat.size(1)\n","\n","    def train(self, iters):\n","        \"\"\"Train over batched data.\n","\n","        Parameters\n","        ----------\n","        iters : torchtext.data.iterator.BucketIterator\n","            The batched data\n","\n","        Returns\n","        -------\n","        dict\n","            The performance and metrics of the training session.\n","\n","        \"\"\"\n","        epoch_loss = 0\n","\n","        self.model.train()\n","        for batch in tqdm.tqdm(iters):\n","            self.model.zero_grad()\n","            y_tilde_b = self.model(batch.form, batch.cue).transpose(1, 2)\n","            loss = self.criterion(y_tilde_b, batch.label)\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","            epoch_loss += loss.item()\n","\n","        results_train = {\n","            \"loss\": epoch_loss / len(iters),\n","        }\n","\n","        return results_train\n","\n","    def evaluate(self, iters):\n","        \"\"\"Evaluate over batched data.\n","\n","        Parameters\n","        ----------\n","        iters : torchtext.data.iterator.BucketIterator\n","            The batched data\n","\n","        Returns\n","        -------\n","        dict\n","            The performance and metrics of the training session.\n","\n","        \"\"\"\n","        tp = 0\n","        n = 0\n","\n","        device = iters.device\n","\n","        y_hat = torch.tensor([], dtype=torch.long).to(device)\n","        y = torch.tensor([], dtype=torch.long).to(device)\n","\n","        self.model.eval()\n","        with torch.no_grad():\n","            for batch in tqdm.tqdm(iters):\n","                y_tilde_b = self.model(batch.form, batch.cue)\n","                y_hat_b = y_tilde_b.argmax(dim=-1)\n","                y_b = batch.label\n","\n","                tp += (y_hat_b == y_b).nonzero().size(0)\n","                n += y_b.size(1)\n","\n","                y_hat = torch.cat((y_hat, y_hat_b.view(-1)))\n","                y = torch.cat((y, y_b.view(-1)))\n","\n","        results_eval = {\n","            \"accuracy\": tp / n,\n","            **self.get_metrics(y.cpu(), y_hat.cpu())\n","        }\n","\n","        return results_eval\n","    \n","    @override\n","    def run(self, epochs, train_iter, eval_iter):\n","        eval_f1_star = 0\n","        n_no_improve = 0\n","\n","        for epoch in range(epochs):\n","\n","            train_res = self.train(train_iter)\n","            eval_res = self.evaluate(eval_iter)\n","\n","            print(eval_res)\n","\n","            append2dict(self.performance[\"train\"],\n","                        train_res)\n","            append2dict(self.performance[\"eval\"],\n","                        eval_res)\n","\n","            if eval_f1_star < self.performance[\"eval\"][\"macro_f1\"][-1]:\n","                eval_f1_star = self.performance[\"eval\"][\"macro_f1\"][-1]\n","                self._update_checkpoint(epoch+1, train_res, eval_res)\n","                print(\"New best F1 score: {:.5f}\".format(eval_f1_star))\n","                n_no_improve = 0\n","            else:\n","                n_no_improve += 1\n","\n","            if n_no_improve == 5:\n","                print(\"Stopping after no improvement for 5 epochs\")\n","                break\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJSjYHVSPh1w","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(M.parameters(), lr=1e-4)\n","\n","criterion = torch.nn.CrossEntropyLoss().cuda()\n","\n","runner = BERTMultiClassRunner(M, criterion, optimizer, LABS.vocab.itos)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"el_PWk6ARo4M","colab_type":"code","colab":{}},"source":["batch_size = 12\n","epochs = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DPnimXEZCsfa","colab_type":"code","colab":{}},"source":["trn_iter = data.BucketIterator(\n","    Xtrain,\n","    device=\"cuda\",\n","    shuffle=True,\n","    batch_size=batch_size\n",")\n","\n","val_iter = data.BucketIterator(\n","    Xdev,\n","    device=\"cuda\",\n","    shuffle=True,\n","    batch_size=1\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BybpgVBXKeap","colab_type":"code","outputId":"40bea21c-4f19-4e17-8b05-c5ef73632aac","executionInfo":{"status":"ok","timestamp":1589152049576,"user_tz":-120,"elapsed":2230280,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["runner.run(epochs, trn_iter, val_iter)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.12it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.95it/s]\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  average, \"true nor predicted\", 'F-score is', len(true_sum)\n","  1%|          | 2/315 [00:00<00:18, 16.90it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9176709641255605, 'precision': 0.32172812402318096, 'recall': 0.2599077849662369, 'macro_f1': 0.2762613690596233, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12690, 68, 0, 0], [0, 928, 407, 0, 0], [0, 30, 116, 0, 0], [0, 26, 7, 0, 0]]}\n","New best F1 score: 0.27626\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.31it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.90it/s]\n","  1%|          | 2/315 [00:00<00:19, 16.44it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9356782511210763, 'precision': 0.5495961499237281, 'recall': 0.4350039944716567, 'macro_f1': 0.477535161626618, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12654, 104, 0, 0], [0, 743, 592, 0, 0], [0, 24, 14, 108, 0], [0, 16, 16, 1, 0]]}\n","New best F1 score: 0.47754\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.29it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.87it/s]\n","  1%|          | 2/315 [00:00<00:18, 16.92it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9286715246636771, 'precision': 0.551094054246034, 'recall': 0.42528660733266266, 'macro_f1': 0.4553439571530804, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12733, 25, 0, 0], [0, 935, 400, 0, 0], [0, 22, 3, 121, 0], [0, 17, 2, 14, 0]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.08it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.14it/s]\n","  1%|          | 2/315 [00:00<00:18, 17.01it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9414938340807175, 'precision': 0.5410957678687112, 'recall': 0.4591665271020492, 'macro_f1': 0.484848820365115, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12703, 55, 0, 0], [0, 724, 611, 0, 0], [0, 21, 2, 123, 0], [0, 10, 1, 22, 0]]}\n","New best F1 score: 0.48485\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.87it/s]\n","100%|██████████| 816/816 [00:28<00:00, 29.03it/s]\n","  1%|          | 2/315 [00:00<00:18, 16.62it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9423346412556054, 'precision': 0.7535864773041598, 'recall': 0.5070433998613046, 'macro_f1': 0.5676176321232804, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12712, 46, 0, 0], [0, 729, 606, 0, 0], [0, 21, 2, 123, 0], [0, 11, 0, 14, 8]]}\n","New best F1 score: 0.56762\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.29it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.74it/s]\n","  1%|          | 2/315 [00:00<00:19, 16.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9516535874439462, 'precision': 0.7595425502891056, 'recall': 0.5974996318302538, 'macro_f1': 0.6589420651954343, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12680, 78, 0, 0], [0, 576, 759, 0, 0], [0, 20, 2, 124, 0], [0, 5, 1, 8, 19]]}\n","New best F1 score: 0.65894\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:17<00:00, 17.54it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.30it/s]\n","  1%|          | 2/315 [00:00<00:22, 13.91it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9522841928251121, 'precision': 0.7504362092576032, 'recall': 0.5970745000515949, 'macro_f1': 0.6576329858327342, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12710, 48, 0, 0], [0, 595, 740, 0, 0], [0, 21, 1, 121, 3], [0, 12, 0, 1, 20]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.27it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.46it/s]\n","  1%|          | 2/315 [00:00<00:19, 15.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9546664798206278, 'precision': 0.7605770200848354, 'recall': 0.6427516921391406, 'macro_f1': 0.689618275444052, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12725, 33, 0, 0], [0, 584, 751, 0, 0], [0, 20, 1, 122, 3], [0, 5, 0, 1, 27]]}\n","New best F1 score: 0.68962\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.07it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.88it/s]\n","  1%|          | 2/315 [00:00<00:21, 14.65it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9520739910313901, 'precision': 0.7799549251071457, 'recall': 0.6238327205516028, 'macro_f1': 0.6833966393513111, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12738, 20, 0, 0], [0, 636, 699, 0, 0], [0, 19, 0, 127, 0], [0, 6, 0, 3, 24]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.19it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.47it/s]\n","  1%|          | 2/315 [00:00<00:22, 13.79it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.960622197309417, 'precision': 0.7479886446587413, 'recall': 0.6856011918845748, 'macro_f1': 0.713824875060184, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12625, 133, 0, 0], [0, 405, 930, 0, 0], [0, 16, 1, 126, 3], [0, 3, 0, 1, 29]]}\n","New best F1 score: 0.71382\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.20it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.96it/s]\n","  1%|          | 2/315 [00:00<00:20, 15.57it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9630044843049327, 'precision': 0.7738099290945103, 'recall': 0.6802490446960876, 'macro_f1': 0.7216453649111376, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12677, 81, 0, 0], [0, 424, 911, 0, 0], [0, 18, 0, 128, 0], [0, 3, 0, 2, 28]]}\n","New best F1 score: 0.72165\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.04it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.49it/s]\n","  1%|          | 2/315 [00:00<00:18, 16.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9588705156950673, 'precision': 0.7518221721678362, 'recall': 0.6702816812432844, 'macro_f1': 0.704503660189501, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12684, 74, 0, 0], [0, 486, 849, 0, 0], [0, 18, 1, 123, 4], [0, 4, 0, 0, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.15it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.97it/s]\n","  1%|          | 2/315 [00:00<00:25, 12.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9611126681614349, 'precision': 0.7850499082122437, 'recall': 0.6816552907254715, 'macro_f1': 0.7240688119054303, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12735, 23, 0, 0], [0, 516, 819, 0, 0], [0, 12, 0, 134, 0], [0, 3, 0, 1, 29]]}\n","New best F1 score: 0.72407\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.97it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.97it/s]\n","  1%|          | 2/315 [00:00<00:21, 14.57it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.960692264573991, 'precision': 0.7818519302688398, 'recall': 0.6766682073594336, 'macro_f1': 0.72078821468573, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12720, 38, 0, 0], [0, 502, 833, 0, 0], [0, 17, 0, 129, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.13it/s]\n","100%|██████████| 816/816 [00:28<00:00, 29.01it/s]\n","  1%|          | 2/315 [00:00<00:18, 17.32it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9605521300448431, 'precision': 0.7743702346862513, 'recall': 0.6732449762354968, 'macro_f1': 0.7157576504222168, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12716, 42, 0, 0], [0, 497, 838, 0, 0], [0, 19, 0, 126, 1], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.92it/s]\n","100%|██████████| 816/816 [00:28<00:00, 29.00it/s]\n","  1%|          | 2/315 [00:00<00:17, 18.10it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9633548206278026, 'precision': 0.7711124488410098, 'recall': 0.6907988542703295, 'macro_f1': 0.7272341239305046, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12648, 110, 0, 0], [0, 391, 944, 0, 0], [0, 17, 1, 128, 0], [0, 3, 0, 1, 29]]}\n","New best F1 score: 0.72723\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.30it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.81it/s]\n","  1%|          | 2/315 [00:00<00:21, 14.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9640554932735426, 'precision': 0.7581170872353857, 'recall': 0.6926825395757535, 'macro_f1': 0.7214758335546462, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12671, 87, 0, 0], [0, 403, 932, 0, 0], [0, 16, 1, 126, 3], [0, 3, 0, 0, 30]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.24it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.44it/s]\n","  1%|          | 2/315 [00:00<00:20, 14.93it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9675588565022422, 'precision': 0.781062152282751, 'recall': 0.7038058070695156, 'macro_f1': 0.737673338998637, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12709, 48, 1, 0], [0, 402, 933, 0, 0], [0, 8, 0, 138, 0], [0, 3, 0, 1, 29]]}\n","New best F1 score: 0.73767\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.00it/s]\n","100%|██████████| 816/816 [00:28<00:00, 29.06it/s]\n","  1%|          | 2/315 [00:00<00:25, 12.21it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9660874439461884, 'precision': 0.7705083840529345, 'recall': 0.7023137461749295, 'macro_f1': 0.7338941199755251, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12633, 125, 0, 0], [0, 340, 995, 0, 0], [0, 14, 1, 131, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.08it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.29it/s]\n","  1%|          | 2/315 [00:00<00:19, 16.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9641255605381166, 'precision': 0.7697324913659148, 'recall': 0.7065911961844541, 'macro_f1': 0.7358803848191334, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12623, 135, 0, 0], [0, 360, 975, 0, 0], [0, 13, 1, 132, 0], [0, 3, 0, 0, 30]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.02it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.65it/s]\n","  1%|          | 2/315 [00:00<00:18, 16.99it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9682595291479821, 'precision': 0.7759131918756231, 'recall': 0.7115126748688028, 'macro_f1': 0.740022947687736, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12690, 65, 3, 0], [0, 376, 959, 0, 0], [0, 5, 0, 141, 0], [0, 3, 0, 1, 29]]}\n","New best F1 score: 0.74002\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.94it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.33it/s]\n","  1%|          | 2/315 [00:00<00:20, 15.37it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9665779147982063, 'precision': 0.7731904829095115, 'recall': 0.6995937954142756, 'macro_f1': 0.7333796101414559, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12652, 106, 0, 0], [0, 351, 984, 0, 0], [0, 15, 1, 130, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.94it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.90it/s]\n","  1%|          | 2/315 [00:00<00:23, 13.44it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9690302690582959, 'precision': 0.7762571584525673, 'recall': 0.7103052818794755, 'macro_f1': 0.7400767730939627, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12684, 72, 2, 0], [0, 356, 979, 0, 0], [0, 7, 1, 138, 0], [0, 3, 0, 1, 29]]}\n","New best F1 score: 0.74008\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.16it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.48it/s]\n","  1%|          | 2/315 [00:00<00:16, 18.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9692404708520179, 'precision': 0.7637807983106212, 'recall': 0.7245707585459484, 'macro_f1': 0.7431973504498103, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12581, 175, 2, 0], [0, 250, 1085, 0, 0], [0, 7, 1, 138, 0], [0, 3, 0, 1, 29]]}\n","New best F1 score: 0.74320\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.05it/s]\n","100%|██████████| 816/816 [00:28<00:00, 29.08it/s]\n","  1%|          | 2/315 [00:00<00:18, 17.03it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.967979260089686, 'precision': 0.7693959405834405, 'recall': 0.7217487893493757, 'macro_f1': 0.7441495619857674, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12626, 130, 2, 0], [0, 314, 1021, 0, 0], [0, 7, 1, 138, 0], [0, 3, 0, 0, 30]]}\n","New best F1 score: 0.74415\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.19it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.49it/s]\n","  1%|          | 2/315 [00:00<00:21, 14.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9698010089686099, 'precision': 0.7676639551606865, 'recall': 0.7212086263624554, 'macro_f1': 0.7431221133255509, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12615, 141, 2, 0], [0, 276, 1059, 0, 0], [0, 7, 1, 138, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.14it/s]\n","100%|██████████| 816/816 [00:27<00:00, 30.12it/s]\n","  1%|          | 2/315 [00:00<00:19, 15.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.969170403587444, 'precision': 0.7720549641387932, 'recall': 0.7147503088987912, 'macro_f1': 0.7414114539849463, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12644, 113, 1, 0], [0, 313, 1022, 0, 0], [0, 8, 1, 137, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.90it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.21it/s]\n","  1%|          | 2/315 [00:00<00:18, 16.77it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9697309417040358, 'precision': 0.7697907765409691, 'recall': 0.7199857232622195, 'macro_f1': 0.7434210024916044, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12623, 134, 1, 0], [0, 285, 1050, 0, 0], [0, 7, 1, 138, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.08it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.31it/s]\n","  1%|          | 2/315 [00:00<00:18, 16.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.969170403587444, 'precision': 0.7748115352998114, 'recall': 0.7107133964080223, 'macro_f1': 0.7401847762207595, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12665, 92, 1, 0], [0, 333, 1002, 0, 0], [0, 9, 1, 136, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.04it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.21it/s]\n","  1%|          | 2/315 [00:00<00:17, 17.56it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9694506726457399, 'precision': 0.7720652222841322, 'recall': 0.7239687263124154, 'macro_f1': 0.7464782659600194, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12642, 114, 2, 0], [0, 310, 1025, 0, 0], [0, 6, 1, 139, 0], [0, 3, 0, 0, 30]]}\n","New best F1 score: 0.74648\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.92it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.47it/s]\n","  1%|          | 2/315 [00:00<00:20, 15.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9704316143497758, 'precision': 0.7814158454928173, 'recall': 0.7104846743499706, 'macro_f1': 0.7422563800983469, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12705, 52, 1, 0], [0, 357, 978, 0, 0], [0, 8, 0, 138, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.10it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.71it/s]\n","  1%|          | 2/315 [00:00<00:24, 12.79it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9665078475336323, 'precision': 0.7693627601977784, 'recall': 0.7143932022940264, 'macro_f1': 0.7401905416644461, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12621, 136, 1, 0], [0, 326, 1009, 0, 0], [0, 11, 1, 134, 0], [0, 3, 0, 0, 30]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.03it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.36it/s]\n","  1%|          | 2/315 [00:00<00:18, 17.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9726036995515696, 'precision': 0.775550726257905, 'recall': 0.7226917961403735, 'macro_f1': 0.7466574057358281, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12685, 70, 3, 0], [0, 309, 1025, 1, 0], [0, 4, 0, 142, 0], [0, 3, 0, 1, 29]]}\n","New best F1 score: 0.74666\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.28it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.89it/s]\n","  1%|          | 2/315 [00:00<00:20, 15.49it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9664377802690582, 'precision': 0.7750377476337607, 'recall': 0.6986363120849585, 'macro_f1': 0.7333927293686673, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12666, 92, 0, 0], [0, 368, 967, 0, 0], [0, 14, 1, 131, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.98it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.54it/s]\n","  1%|          | 2/315 [00:00<00:22, 13.95it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9705717488789237, 'precision': 0.7789633980642099, 'recall': 0.7103562436954407, 'macro_f1': 0.7415721753510425, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12690, 67, 1, 0], [0, 338, 997, 0, 0], [0, 9, 1, 136, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.28it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.70it/s]\n","  1%|          | 2/315 [00:00<00:18, 17.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9684697309417041, 'precision': 0.7763443763861807, 'recall': 0.7062514469425827, 'macro_f1': 0.7381114866733987, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12678, 79, 1, 0], [0, 355, 980, 0, 0], [0, 10, 1, 135, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.88it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.52it/s]\n","  1%|          | 2/315 [00:00<00:21, 14.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.968960201793722, 'precision': 0.7747248141735519, 'recall': 0.7175289381076841, 'macro_f1': 0.7438772476097135, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12664, 92, 2, 0], [0, 337, 998, 0, 0], [0, 8, 1, 137, 0], [0, 3, 0, 0, 30]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.79it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.33it/s]\n","  1%|          | 2/315 [00:00<00:17, 18.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9723934977578476, 'precision': 0.7728279139733374, 'recall': 0.7298456286388749, 'macro_f1': 0.7502824875091049, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12636, 120, 2, 0], [0, 261, 1074, 0, 0], [0, 8, 0, 138, 0], [0, 3, 0, 0, 30]]}\n","New best F1 score: 0.75028\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.94it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.74it/s]\n","  1%|          | 2/315 [00:00<00:22, 13.65it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9720431614349776, 'precision': 0.7759141599009405, 'recall': 0.718209905080786, 'macro_f1': 0.7450612107455982, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12664, 93, 1, 0], [0, 292, 1043, 0, 0], [0, 8, 1, 137, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.86it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.88it/s]\n","  1%|          | 2/315 [00:00<00:23, 13.44it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9698710762331838, 'precision': 0.7722797859292755, 'recall': 0.7150412095776926, 'macro_f1': 0.7415851634179929, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12653, 103, 2, 0], [0, 312, 1023, 0, 0], [0, 8, 1, 137, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.14it/s]\n","100%|██████████| 816/816 [00:28<00:00, 29.03it/s]\n","  1%|          | 2/315 [00:00<00:19, 15.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9702914798206278, 'precision': 0.7740743070212096, 'recall': 0.7155505007125731, 'macro_f1': 0.7425066984835602, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12665, 91, 2, 0], [0, 319, 1016, 0, 0], [0, 7, 1, 138, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.91it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.95it/s]\n","  1%|          | 2/315 [00:00<00:22, 13.90it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9695908071748879, 'precision': 0.7699511134751877, 'recall': 0.7169777246432838, 'macro_f1': 0.7418955184941259, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12625, 132, 1, 0], [0, 287, 1048, 0, 0], [0, 9, 1, 136, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.07it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.23it/s]\n","  1%|          | 2/315 [00:00<00:21, 14.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9735846412556054, 'precision': 0.7771097421141425, 'recall': 0.7295884065248165, 'macro_f1': 0.7518953308467236, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12666, 90, 2, 0], [0, 275, 1060, 0, 0], [0, 7, 0, 139, 0], [0, 3, 0, 0, 30]]}\n","New best F1 score: 0.75190\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 16.91it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.36it/s]\n","  1%|          | 2/315 [00:00<00:20, 15.39it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9709921524663677, 'precision': 0.7726416096989774, 'recall': 0.7164736120172395, 'macro_f1': 0.7428210283498293, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12642, 115, 1, 0], [0, 283, 1052, 0, 0], [0, 10, 1, 135, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.28it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.37it/s]\n","  1%|          | 2/315 [00:00<00:19, 16.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9662976457399103, 'precision': 0.7797768670125051, 'recall': 0.6964162803179303, 'macro_f1': 0.7337282590111445, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12688, 70, 0, 0], [0, 389, 946, 0, 0], [0, 18, 1, 127, 0], [0, 3, 0, 0, 30]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.15it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.62it/s]\n","  1%|          | 2/315 [00:00<00:19, 15.88it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.968890134529148, 'precision': 0.7802004136126197, 'recall': 0.7014781280716906, 'macro_f1': 0.7370250379226798, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12693, 65, 0, 0], [0, 361, 974, 0, 0], [0, 14, 0, 132, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.02it/s]\n","100%|██████████| 816/816 [00:27<00:00, 29.20it/s]\n","  1%|          | 2/315 [00:00<00:21, 14.86it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.9705016816143498, 'precision': 0.7781918277885638, 'recall': 0.7085711481767409, 'macro_f1': 0.7404111963765323, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12684, 73, 1, 0], [0, 331, 1004, 0, 0], [0, 12, 0, 134, 0], [0, 3, 0, 1, 29]]}\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 315/315 [00:18<00:00, 17.01it/s]\n","100%|██████████| 816/816 [00:28<00:00, 28.99it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'accuracy': 0.968189461883408, 'precision': 0.779147127405315, 'recall': 0.7017365961935595, 'macro_f1': 0.7366661077331859, 'confusion_matrix': [[0, 0, 0, 0, 0], [0, 12689, 69, 0, 0], [0, 368, 967, 0, 0], [0, 12, 1, 133, 0], [0, 3, 0, 1, 29]]}\n","Stopping after no improvement for 5 epochs\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Y0hNJlmYKehW","colab_type":"code","outputId":"33d0a8e6-d2f8-4f0a-caee-3fa2ec9d2226","executionInfo":{"status":"ok","timestamp":1589152097080,"user_tz":-120,"elapsed":29082,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["dev_res = runner.evaluate(val_iter)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 816/816 [00:28<00:00, 28.52it/s]\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"jtlvEH6bdosM","colab_type":"code","outputId":"21ba69ce-73e3-407f-9f7d-465f1161fb59","executionInfo":{"status":"ok","timestamp":1589152107114,"user_tz":-120,"elapsed":565,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["print(\"*\"*21)\n","print(\"{} {}\".format(\"BiLSTM-C\", \"BERT_base\"))\n","print(\"Results:\")\n","for i in [\"accuracy\", \"precision\", \"recall\", \"macro_f1\"]:\n","  print(\"\\t{}: {:2f}\".format(i, dev_res[i]))\n","print(\"Confusion Matrix: \\n\")\n","for i in dev_res[\"confusion_matrix\"]:\n","  print(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["*********************\n","BiLSTM-C BERT_base\n","Results:\n","\taccuracy: 0.968189\n","\tprecision: 0.779147\n","\trecall: 0.701737\n","\tmacro_f1: 0.736666\n","Confusion Matrix: \n","\n","[0, 0, 0, 0, 0]\n","[0, 12689, 69, 0, 0]\n","[0, 368, 967, 0, 0]\n","[0, 12, 1, 133, 0]\n","[0, 3, 0, 1, 29]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wKka_JFbdtzy","colab_type":"code","outputId":"d33d7d16-2561-4152-f7d0-75348d68aa71","executionInfo":{"status":"ok","timestamp":1589152291228,"user_tz":-120,"elapsed":4069,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["runner.save(dirpath=\"Saves/BiLSTM-CE/BERT_base\", checkpoint=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BiBERTLSTM. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"JJxiRvkE3nso","colab_type":"code","colab":{}},"source":["import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZ3Am4cU3g7C","colab_type":"code","colab":{}},"source":["with open(os.path.join(\"Saves/BiLSTM-CE/BERT_base\", \"labels\"), \"wb\") as o:\n","  pickle.dump(LABS.vocab, o)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gfwrOGj53UhU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"epsZ_REQKe6d","colab_type":"text"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"JNn4lVX73UzP","colab_type":"code","colab":{}},"source":["import glob\n","import argparse\n","import random\n","import torch\n","import torchtext\n","from torchtext import data\n","import NSR\n","import pickle\n","import os\n","import json\n","from collections import OrderedDict, defaultdict\n","from pathlib import Path\n","from transformers import BertTokenizer, BertModel\n","\n","\n","class LabelMapper():\n","  \n","  def __init__(self, vocab_stoi, vocab_itos):\n","    self.label2ind = vocab_stoi\n","    self.labelset = vocab_itos\n","    \n","  def index2label(self, x):\n","    return self.labelset[x]\n","  \n","  def label2index(self, x):\n","    return self.label2ind[x]\n","        \n","  def __call__(self, x):\n","    if type(x) == int:\n","      self.index2label(x)\n","    elif type(x) == str:\n","      self.label2index(x)\n","    else:\n","      raise ValueError(\"This is not a valid key\")\n","\n","\n","class BERTEvaluator():\n","  \"\"\"Use a saved model to evaluate on held out dataset.\n","\n","  Loads a saved model and vocabularies to be used for\n","  predicting new data.\n","  \"\"\"\n","\n","  def __init__(self, saved_model_dir=None):\n","    self.work_dir = saved_model_dir\n","    \n","    with open(os.path.join(self.work_dir, \"labels\"), \"rb\") as f:\n","      self.lab_voc = pickle.load(f)\n","    \n","    modelfile = glob.glob(os.path.join(self.work_dir, \"model_epoch*.pt\"))[0]\n","    state_dict = torch.load(modelfile)[\"model_state_dict\"]\n","    self.device = state_dict[\"fc.bias\"].device\n","\n","    tokenbert = BertTokenizer.from_pretrained('bert-base-cased', \n","                                              do_lower_case=False)\n","\n","    bert = BertModel.from_pretrained('bert-base-cased')\n","\n","    model = BiBERTLSTM(bert, 768, \n","               n_neurons=250, n_layers=2, \n","               output_dim=5)\n","    \n","    model.to(self.device)\n","    \n","    model.load_state_dict(state_dict)\n","    self.model = model\n","    self.model.eval()\n","\n","    self.FORM = data.Field(batch_first = True,\n","                           include_lengths = True,\n","                           use_vocab = False,\n","                           tokenize=tokenbert.tokenize,\n","                           preprocessing=tokenbert.convert_tokens_to_ids,\n","                           init_token = tokenbert.cls_token_id,\n","                           eos_token = tokenbert.sep_token_id,\n","                           pad_token = tokenbert.pad_token_id,\n","                           unk_token = tokenbert.unk_token_id)\n","\n","    self.CUE = data.Field(batch_first = True,\n","                          include_lengths = False,\n","                          use_vocab = False,\n","                          tokenize=tokenbert.tokenize,\n","                          preprocessing=tokenbert.convert_tokens_to_ids,\n","                          init_token = tokenbert.cls_token_id,\n","                          eos_token = tokenbert.sep_token_id,\n","                          pad_token = tokenbert.pad_token_id,\n","                          unk_token = tokenbert.unk_token_id)\n","\n","    \n","    self.LABS = data.Field(batch_first=True, unk_token=None)\n","    self.LABS.vocab = self.lab_voc\n","\n","    self.mapp = LabelMapper(self.LABS.vocab.stoi,\n","                            self.LABS.vocab.itos)\n","    \n","    self.correction_log = []\n","    self.pred_seqs = set()\n","\n","\n","  def map_node(self, id, f, l, x):\n","    return {\"id\": str(id), \n","            \"form\": f, \n","            \"properties\": {\"lemma\": l, \"xpos\": x}}\n","  \n","  def map_back_gold(self, sentence):\n","    out = sentence.copy()\n","  \n","    form = out.pop(\"form\")\n","    lemma = out.pop(\"lemma\")\n","    xpos = out.pop(\"xpos\")\n","    cue = out.pop(\"cue\")\n","    scope = out.pop(\"scope\")\n","    negation = out.pop(\"negation\")\n","\n","    nodes = []\n","\n","    if out[\"negations\"] == 0:\n","      for i in range(len(form)):\n","        nodes.append(self.map_node(i, form[i], lemma[i], xpos[i]))\n","  \n","    else:\n","      for i in range(len(form)):\n","        node = self.map_node(i, form[i], lemma[i], xpos[i])\n","        if negation[i] == \"T\":\n","          node[\"negation\"] = [{\"id\": 0}]\n","        elif negation[i] == \"F\":\n","          node[\"negation\"] = [{\"id\": 0, \"scope\": scope[i]}]\n","        elif negation[i] == \"C\":\n","          node[\"negation\"] = [{\"id\": 0, \"cue\": cue[i]}]\n","        elif negation[i] == \"A\":\n","          node[\"negation\"] = [{\"id\": 0, \"cue\": cue[i], \"scope\": scope[i]}]\n","        else:\n","          node[\"negation\"] = [{\"id\": 0}]\n","\n","        nodes.append(node)\n","\n","    out[\"nodes\"] = nodes\n","    return out\n","  \n","  def map_back_pred(self, sentence):\n","    out = sentence.copy()\n","  \n","    form = out.pop(\"form\")\n","    lemma = out.pop(\"lemma\")\n","    xpos = out.pop(\"xpos\")\n","    cue = out.pop(\"cue\")\n","    scope = out.pop(\"scope\")\n","    negation = out.pop(\"negation\")\n","\n","    nodes = []\n","\n","    # To handle logic in the 'convert.py' file\n","    # need to set negations to 0 if there are no predicted cues\n","\n","    if set(negation).issubset(set(\"T\")):\n","      out[\"negations\"] = 0\n","    else:\n","      out[\"negations\"] = 1\n","\n","    if out[\"negations\"] == 0:\n","      for i in range(len(form)):\n","        nodes.append(self.map_node(i, form[i], lemma[i], xpos[i]))\n","  \n","    else:\n","      for i in range(len(form)):\n","        node = self.map_node(i, form[i], lemma[i], xpos[i])\n","        if negation[i] == \"T\":\n","          node[\"negation\"] = [{\"id\": 0}]\n","        elif negation[i] == \"F\":\n","          node[\"negation\"] = [{\"id\": 0, \"scope\": scope[i]}]\n","        elif negation[i] == \"C\":\n","          node[\"negation\"] = [{\"id\": 0, \"cue\": cue[i]}]\n","        elif negation[i] == \"A\":\n","          node[\"negation\"] = [{\"id\": 0, \"cue\": cue[i], \"scope\": scope[i]}]\n","        else:\n","          node[\"negation\"] = [{\"id\": 0}]\n","\n","        nodes.append(node)\n","\n","    out[\"nodes\"] = nodes\n","    return out  \n","\n","  \n","  def _correct_preds(self, pred_labs, id, src):\n","    \"\"\"Apply a simple constraint on the predictions.\"\"\"\n","\n","    n_cues = pred_labs.count(\"A\") + pred_labs.count(\"C\")\n","\n","    # No predicted cues, but has scope\n","    if n_cues == 0 and not set(pred_labs).issubset(set(\"T\")):\n","      # Correct everything to true\n","      out_labs = [\"T\"]*len(pred_labs)\n","      self.correction_log.append({\"id\": id, \"source\": src})\n","      return out_labs\n","    \n","    return pred_labs\n","\n","  \n","  def pred(self, batch, apply_dk=False):\n","    with torch.no_grad():\n","      form_b = self.FORM.process(\n","          [self.FORM.preprocess(batch[\"form\"])],\n","          device=self.device\n","      )\n","\n","      cue_b = self.CUE.process(\n","          [self.CUE.preprocess(batch[\"cue\"])],\n","          device=self.device\n","      )\n","      \n","      lab_b = self.LABS.process([batch[\"negation\"]], device=self.device)\n","\n","      y_tilde = self.model(form_b, cue_b)\n","      y_hat = y_tilde.argmax(dim=-1).cpu().flatten().tolist()\n","      y_hat = [self.mapp.index2label(l) for l in y_hat]\n","      if apply_dk:\n","        y_hat = self._correct_preds(y_hat, batch[\"id\"], batch[\"source\"])\n","      \n","      self.pred_seqs.add(tuple(set(y_hat)))\n","\n","      y_b = batch[\"negation\"]\n","      return y_b, y_hat\n","  \n","  def output_preds(self, eval_file, results_file=None, apply_dk=False):\n","    if not results_file:\n","      results_file = \"eval_pred.epe\"\n","\n","    out_file = os.path.join(self.work_dir, results_file)\n","\n","    if os.path.isfile(out_file):\n","      raise Exception(\"There is already a file there\")\n","    \n","    with open(eval_file) as f, open(out_file, \"wt\") as r:\n","      for line in f:\n","        sent = json.loads(line)\n","        _, y_pred = self.pred(sent, apply_dk)\n","        sent[\"negation\"] = y_pred\n","        sent = self.map_back_pred(sent)\n","        json.dump(sent, r)\n","        r.write(\"\\n\")\n","    \n","    n_corr = len(self.correction_log)\n","    if apply_dk and n_corr > 0:\n","      with open(os.path.join(self.work_dir, \"correction_log.txt\"), \"w\") as log:\n","        for corr in self.correction_log:\n","          json.dump(corr, log)\n","          log.write(\"\\n\")\n","\n","      print(\"{} corrections applied, see correction_log.txt\".format(n_corr))\n","    \n","    print(\"File saved to {}\".format(out_file))\n","\n","\n","  def output_preds_tidy(self, eval_file, results_file=None, apply_dk=False):\n","    if not results_file:\n","      results_file = \"eval_pred_tidy.epe\"\n","\n","    out_file = os.path.join(self.work_dir, results_file)\n","\n","    if os.path.isfile(out_file):\n","      raise Exception(\"There is already a file there\")\n","    \n","    with open(eval_file) as f, open(out_file, \"wt\") as r:\n","      for line in f:\n","        sent = json.loads(line)\n","        _, y_pred = self.pred(sent, apply_dk)\n","        sent[\"negation\"] = y_pred\n","        json.dump(sent, r)\n","        r.write(\"\\n\")\n","    \n","    print(\"File saved to {}\".format(out_file))\n","\n","\n","  def _load(self, argname, module, *args, **kwargs):\n","    item = self.setup[argname][\"type\"]\n","    item_args = dict(self.setup[argname][\"args\"])\n","    if sum([kwarg in item_args for kwarg in kwargs]) != 0:\n","      raise ValueError(\"Args set in config file cannot be overwritten\")\n","    item_args.update(kwargs)\n","    \n","    return getattr(module, item)(*args, **item_args)\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZR6gIO_87MrH","colab_type":"code","colab":{}},"source":["ev = BERTEvaluator(\"Saves/BiLSTM-CE/BERT_base\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mw00K0ih84S4","colab_type":"code","outputId":"2bd06ee8-0894-4afa-a9e4-c0423dbc6fb0","executionInfo":{"status":"ok","timestamp":1589201925866,"user_tz":-120,"elapsed":36667,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["ev.output_preds(eval_file=\"DataFiles/cde.epe\", \n","                results_file=\"eval_pred_final.epe\",\n","                apply_dk=False)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["File saved to Saves/BiLSTM-CE/BERT_base/eval_pred_final.epe\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mwrib5XtKD8u","colab_type":"code","outputId":"d92b0b60-0d12-4778-835b-769337b3c9c2","executionInfo":{"status":"ok","timestamp":1589201969496,"user_tz":-120,"elapsed":36918,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["ev.output_preds(eval_file=\"DataFiles/cde.epe\", \n","                results_file=\"eval_pred_corr_final.epe\",\n","                apply_dk=True)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["4 corrections applied, see correction_log.txt\n","File saved to Saves/BiLSTM-CE/BERT_base/eval_pred_corr_final.epe\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HuO0UuQit_R1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7411ea47-29cf-448e-a407-c8942107bb38","executionInfo":{"status":"ok","timestamp":1589202065305,"user_tz":-120,"elapsed":36398,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}}},"source":["ev.output_preds_tidy(eval_file=\"DataFiles/cde.epe\", \n","                results_file=\"eval_pred_tidy.epe\",\n","                apply_dk=False)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["File saved to Saves/BiLSTM-CE/BERT_base/eval_pred_tidy.epe\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tAAVwRBftoIQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8b617c56-34a5-41d9-b206-049765e72e86","executionInfo":{"status":"ok","timestamp":1589202106253,"user_tz":-120,"elapsed":35978,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}}},"source":["ev.output_preds_tidy(eval_file=\"DataFiles/cde.epe\", \n","                results_file=\"eval_pred_corr_tidy.epe\",\n","                apply_dk=True)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["File saved to Saves/BiLSTM-CE/BERT_base/eval_pred_corr_tidy.epe\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a4rXSpzTKjSG","colab_type":"text"},"source":["# Evaluation With `score.py`"]},{"cell_type":"code","metadata":{"id":"9yYFaU3bKuDa","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append(\"negation\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XX80e6hHKun0","colab_type":"code","colab":{}},"source":["from negation import score, convert"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1NxTmMWK36A","colab_type":"code","colab":{}},"source":["s_gold = convert.read_negations(\"EvalFiles/eval_gold.epe\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hh2YCkj_K8gS","colab_type":"code","colab":{}},"source":["s_pred = convert.read_negations(\"Saves/BiLSTM-CE/BERT_base/eval_pred_corr_final.epe\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIsf796ELHPL","colab_type":"code","colab":{}},"source":["file = \"BERT_base_corr_score_final.txt\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfU8yQZVLSR2","colab_type":"code","outputId":"5781bcd5-3055-431a-fec0-b5cb7ad0cc07","executionInfo":{"status":"ok","timestamp":1589202147111,"user_tz":-120,"elapsed":795,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd negation"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/in5550-exam/negation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"waMgAtfMLuaw","colab_type":"code","colab":{}},"source":["score.starsem_score(s_gold, s_pred, file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrASAvr2MGJH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ZcMHlllMtSk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e178e799-d39b-4055-a383-b9997a168fff","executionInfo":{"status":"ok","timestamp":1589166671000,"user_tz":-120,"elapsed":606,"user":{"displayName":"Sigurd Hylin","photoUrl":"","userId":"13345297748726139219"}}},"source":["%cd .."],"execution_count":47,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/in5550-exam\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HTVRrAUtsp4n","colab_type":"code","colab":{}},"source":["3"],"execution_count":0,"outputs":[]}]}